{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simport matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing data, spray data for the test set (2008,2010,2012,2014) is not provided. Therefore, spray info is not used for the analysis\n",
    "train = pd.read_csv('./assets/train.csv')\n",
    "test =pd.read_csv('./assets/test.csv')\n",
    "weather = pd.read_csv('./assets/weather.csv')\n",
    "spray =pd.read_csv('./assets/spray.csv')\n",
    "mapdata = np.loadtxt(\"./assets/mapdata_copyright_openstreetmap_contributors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "train['Date'] = pd.to_datetime(train['Date'], format='%Y-%m-%d')\n",
    "test['Date'] = pd.to_datetime(test['Date'], format='%Y-%m-%d')\n",
    "weather['Date'] = pd.to_datetime(weather['Date'], format='%Y-%m-%d')\n",
    "spray['Date'] = pd.to_datetime(spray['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['week'] = train['Date'].dt.weekofyear\n",
    "train['year'] = train['Date'].dt.year\n",
    "test['week'] = test['Date'].dt.weekofyear\n",
    "test['year'] = test['Date'].dt.year\n",
    "spray['year']=spray['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Date', u'Address', u'Species', u'Block', u'Street', u'Trap',\n",
       "       u'AddressNumberAndStreet', u'Latitude', u'Longitude',\n",
       "       u'AddressAccuracy', u'NumMosquitos', u'WnvPresent', u'week', u'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(train[[1,3,4,5,6,9,10]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Species</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>WnvPresent</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-05-29</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                 Species  Latitude  Longitude  WnvPresent  week  \\\n",
       "0 2007-05-29  CULEX PIPIENS/RESTUANS  41.95469 -87.800991           0    22   \n",
       "\n",
       "   year  \n",
       "0  2007  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test =test.drop(test[[0,2,4,5,6,7,10]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Species</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX PIPIENS</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX SALINARIUS</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>CULEX TERRITANS</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                 Species  Latitude  Longitude  week  year\n",
       "0 2008-06-11  CULEX PIPIENS/RESTUANS  41.95469 -87.800991    24  2008\n",
       "1 2008-06-11          CULEX RESTUANS  41.95469 -87.800991    24  2008\n",
       "2 2008-06-11           CULEX PIPIENS  41.95469 -87.800991    24  2008\n",
       "3 2008-06-11        CULEX SALINARIUS  41.95469 -87.800991    24  2008\n",
       "4 2008-06-11         CULEX TERRITANS  41.95469 -87.800991    24  2008"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train , pd.get_dummies(train['Species'])], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.concat([test , pd.get_dummies(test['Species'])], axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>week</th>\n",
       "      <th>year</th>\n",
       "      <th>CULEX ERRATICUS</th>\n",
       "      <th>CULEX PIPIENS</th>\n",
       "      <th>CULEX PIPIENS/RESTUANS</th>\n",
       "      <th>CULEX RESTUANS</th>\n",
       "      <th>CULEX SALINARIUS</th>\n",
       "      <th>CULEX TARSALIS</th>\n",
       "      <th>CULEX TERRITANS</th>\n",
       "      <th>UNSPECIFIED CULEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>24</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Latitude  Longitude  week  year  CULEX ERRATICUS  CULEX PIPIENS  \\\n",
       "0 2008-06-11  41.95469 -87.800991    24  2008                0              0   \n",
       "1 2008-06-11  41.95469 -87.800991    24  2008                0              0   \n",
       "2 2008-06-11  41.95469 -87.800991    24  2008                0              1   \n",
       "3 2008-06-11  41.95469 -87.800991    24  2008                0              0   \n",
       "4 2008-06-11  41.95469 -87.800991    24  2008                0              0   \n",
       "\n",
       "   CULEX PIPIENS/RESTUANS  CULEX RESTUANS  CULEX SALINARIUS  CULEX TARSALIS  \\\n",
       "0                       1               0                 0               0   \n",
       "1                       0               1                 0               0   \n",
       "2                       0               0                 0               0   \n",
       "3                       0               0                 1               0   \n",
       "4                       0               0                 0               0   \n",
       "\n",
       "   CULEX TERRITANS  UNSPECIFIED CULEX  \n",
       "0                0                  0  \n",
       "1                0                  0  \n",
       "2                0                  0  \n",
       "3                0                  0  \n",
       "4                1                  0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test =test.drop(test[[1]], axis=1)\n",
    "train =train.drop(train[[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w30 = pd.read_csv('weather_ave_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w30 = w30.drop('Datetime_Date', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w30['Date'] = pd.to_datetime(w30['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the weather data to the train and test data\n",
    "train_add =train.join(w30.set_index('Date'), on='Date')\n",
    "test_add = test.join(w30.set_index('Date'), on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    101948\n",
       "1     14345\n",
       "Name: UNSPECIFIED CULEX, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_add['UNSPECIFIED CULEX'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_add['UNSPECIFIED CULEX']= 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y =train_add['WnvPresent']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_add = train_add.drop('WnvPresent', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khaterehmohajery1/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report,roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold ,train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Date', u'Latitude', u'Longitude', u'week', u'year',\n",
       "       u'CULEX ERRATICUS', u'CULEX PIPIENS', u'CULEX PIPIENS/RESTUANS',\n",
       "       u'CULEX RESTUANS', u'CULEX SALINARIUS', u'CULEX TARSALIS',\n",
       "       u'CULEX TERRITANS', u'Tmax', u'Tmin', u'Tavg', u'Depart', u'DewPoint',\n",
       "       u'WetBulb', u'Heat', u'Cool', u'PrecipTotal', u'StnPressure',\n",
       "       u'SeaLevel', u'ResultSpeed', u'ResultDir', u'AvgSpeed', u'HZ', u'VC',\n",
       "       u'FU', u'BC', u'SQ', u'FG+', u'MI', u'TS', u'DZ', u'RA', u'BR', u'FG',\n",
       "       u'SN', u'UNSPECIFIED CULEX'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_add.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X =train_add[[u'Latitude', u'Longitude', u'week', u'year',\n",
    "       u'CULEX ERRATICUS', u'CULEX PIPIENS', u'CULEX PIPIENS/RESTUANS',\n",
    "       u'CULEX RESTUANS', u'CULEX SALINARIUS', u'CULEX TARSALIS',\n",
    "       u'CULEX TERRITANS', u'Tmax', u'Tmin', u'Tavg', u'Depart', u'DewPoint',\n",
    "       u'WetBulb', u'Heat', u'Cool', u'PrecipTotal', u'StnPressure',\n",
    "       u'SeaLevel', u'ResultSpeed', u'ResultDir', u'AvgSpeed', u'HZ', u'VC',\n",
    "       u'FU', u'BC', u'SQ', u'FG+', u'MI', u'TS', u'DZ', u'RA', u'BR', u'FG',\n",
    "       u'SN', u'UNSPECIFIED CULEX']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_add= test_add.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X= scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_add =scaler.fit_transform(test_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e603203e54cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mgsrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mgsrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'best parameters for the model:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgsrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'best score on train:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgsrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaterehmohajery1/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \"\"\"\n\u001b[0;32m--> 940\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaterehmohajery1/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    560\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 562\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m           for train, test in cv.split(X, y, groups))\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaterehmohajery1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaterehmohajery1/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Grid search over Random Forest parameters\n",
    "# model evaluation function\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "\n",
    "    confusion = pd.DataFrame(conmat, index=['1', '0'],\n",
    "                         columns=['predicted_1','predicted_0'])\n",
    "\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print 'confusion matrix:'\n",
    "    print confusion\n",
    "    print 'classification_report:'\n",
    "    print cr\n",
    "    print 'Accuracy of the model on test:',a\n",
    "    return probabilities\n",
    "#params = {'max_features ': [0.5,1.0],'max_depth':[0.5,1.0],'n_estimators':[5,10]}\n",
    "max_depths = [0.3, 0.5,1.0]\n",
    "max_features = [0.3,0.5,1.0]\n",
    "n_estimators = [5000]\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1,random_state = 33, class_weight='balanced')\n",
    "gsrf = GridSearchCV(estimator = rf,param_grid=dict(max_depth = max_depths, max_features=max_features,n_estimators=n_estimators), n_jobs=-1,cv=3,scoring='roc_auc')\n",
    "gsrf.fit(X_train, y_train)\n",
    "print 'best parameters for the model:',gsrf.best_params_\n",
    "print 'best score on train:',gsrf.best_score_\n",
    "probability = evaluate_model(gsrf.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters for the model: {'n_neighbors': 26}\n",
      "best score on train: 0.781501809087\n",
      "confusion matrix:\n",
      "   predicted_1  predicted_0\n",
      "1            0          182\n",
      "0            0         3285\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      3285\n",
      "          1       0.00      0.00      0.00       182\n",
      "\n",
      "avg / total       0.90      0.95      0.92      3467\n",
      "\n",
      "Accuracy of the model on test: 0.947505047592\n"
     ]
    }
   ],
   "source": [
    "##Grid search over Knn parameters\n",
    "# model evaluation function\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "\n",
    "    confusion = pd.DataFrame(conmat, index=['1', '0'],\n",
    "                         columns=['predicted_1','predicted_0'])\n",
    "\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print 'confusion matrix:'\n",
    "    print confusion\n",
    "    print 'classification_report:'\n",
    "    print cr\n",
    "    print 'Accuracy of the model on test:',a\n",
    "    return probabilities\n",
    "\n",
    "n_neighbors =  range(5, 30)\n",
    "knn = KNeighborsClassifier()\n",
    "gsknn = GridSearchCV(estimator = knn,param_grid=dict( n_neighbors=n_neighbors), n_jobs=-1,cv=3,scoring='roc_auc')\n",
    "gsknn.fit(X_train, y_train)\n",
    "print 'best parameters for the model:',gsknn.best_params_\n",
    "print 'best score on train:',gsknn.best_score_\n",
    "probability = evaluate_model(gsknn.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions =gsknn.best_estimator_.predict(test_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pd.Series(predictions)\n",
    "submit= pd.concat([test['Id'], predictions], axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.columns=['Id','WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv('submission.csv',index_label=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters for the model: {'penalty': 'l1', 'C': 1.0}\n",
      "best score on train: 0.835144536791\n",
      "confusion matrix:\n",
      "   predicted_1  predicted_0\n",
      "1            0          182\n",
      "0            1         3284\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      3285\n",
      "          1       0.00      0.00      0.00       182\n",
      "\n",
      "avg / total       0.90      0.95      0.92      3467\n",
      "\n",
      "Accuracy of the model on test: 0.947216613787\n"
     ]
    }
   ],
   "source": [
    "##Grid search over Logestic Regression parameters\n",
    "# model evaluation function\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "   \n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "\n",
    "    confusion = pd.DataFrame(conmat, index=['1', '0'],\n",
    "                        columns=['predicted_1','predicted_0'])\n",
    "\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "   \n",
    "    print 'confusion matrix:'\n",
    "    print confusion\n",
    "    print 'classification_report:'\n",
    "    print cr\n",
    "    print 'Accuracy of the model on test:',a\n",
    "    return probabilities\n",
    "\n",
    "penalty =  ['l2','l1']\n",
    "C = [0.1,1.0,10]\n",
    "lg = LogisticRegression()\n",
    "gslg = GridSearchCV(estimator = lg,param_grid=dict(C=C, penalty=penalty), n_jobs=-1,cv=3,scoring='roc_auc')\n",
    "gslg.fit(X_train, y_train)\n",
    "print 'best parameters for the model:',gslg.best_params_\n",
    "print 'best score on train:',gslg.best_score_\n",
    "probability = evaluate_model(gslg.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters for the model: {'max_features': 0.5, 'n_estimators': 50, 'max_depth': 1.0}\n",
      "best score on train: 0.815676865299\n",
      "confusion matrix:\n",
      "   predicted_1  predicted_0\n",
      "1            0          182\n",
      "0            0         3285\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      3285\n",
      "          1       0.00      0.00      0.00       182\n",
      "\n",
      "avg / total       0.90      0.95      0.92      3467\n",
      "\n",
      "Accuracy of the model on test: 0.947505047592\n"
     ]
    }
   ],
   "source": [
    "##Grid search over Gradiant boosting\n",
    "# model evaluation function\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    probabilities = model.predict_proba(X_test)\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    conmat = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "    confusion = pd.DataFrame(conmat, index=['1', '0'],\n",
    "                         columns=['predicted_1','predicted_0'])\n",
    "    cr = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print 'confusion matrix:'\n",
    "    print confusion\n",
    "    print 'classification_report:'\n",
    "    print cr\n",
    "    print 'Accuracy of the model on test:',a\n",
    "    return probabilities\n",
    "max_features = [0.1,.5,1.0]\n",
    "max_depth = [0.1,0.5,1.0]\n",
    "n_estimators = [3, 5, 10, 50]\n",
    "gbc = GradientBoostingClassifier()\n",
    "gsgbc = GridSearchCV(estimator = gbc,param_grid=dict(max_features=max_features, max_depth=max_depth, n_estimators=n_estimators), n_jobs=-1,cv=3, scoring = 'roc_auc')\n",
    "gsgbc.fit(X_train, y_train)\n",
    "print 'best parameters for the model:',gsgbc.best_params_\n",
    "print 'best score on train:',gsgbc.best_score_\n",
    "probability = evaluate_model(gsgbc.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
